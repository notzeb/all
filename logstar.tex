\documentclass[letterpaper,11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{fullpage}
\usepackage{verbatim}
\usepackage{mathrsfs}
\usepackage{mathtools}

\DeclareMathOperator{\sech}{sech}

\begin{document}

\makeatletter
\newtheorem*{rep@theorem}{\rep@title}
\newcommand{\newreptheorem}[2]{%
\newenvironment{rep#1}[1]{%
 \def\rep@title{#2 \ref{##1}}%
 \begin{rep@theorem}}%
 {\end{rep@theorem}}}
\makeatother

\newtheorem{thm}{Theorem}
\newreptheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newreptheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newreptheorem{lem}{Lemma}
\newtheorem{quest}{Question}
\newtheorem*{conj*}{Conjecture}
\newtheorem*{thm*}{Theorem}

\theoremstyle{definition}
\newtheorem{defn}{Definition}

\theoremstyle{remark}
\newtheorem{rem}{Remark}

\newcommand{\Rho}{\mathrm{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\gk}{\kappa}
\newcommand{\gS}{\Sigma}
\newcommand{\gl}{\lambda}
\newcommand{\gt}{\theta}

\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\bA}{\mathbb{A}}
\newcommand{\bB}{\mathbb{B}}
\newcommand{\bC}{\mathbb{C}}
\newcommand{\bD}{\mathbb{D}}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bG}{\mathbb{G}}
\newcommand{\bI}{\mathbb{I}}
\newcommand{\bL}{\mathbb{L}}
\newcommand{\bM}{\mathbb{M}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\fA}{\mathbf{A}}
\newcommand{\fB}{\mathbf{B}}
\newcommand{\fG}{\mathbf{G}}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}

\newcommand{\cC}{\mathcal{C}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}

\newcommand{\fp}{\mathfrak{p}}

\title{Interpolating $\log^*$}
\author{}
\date{}
\maketitle

Imagine that we wish to find a function perfectly in between $x$ and $e^x$. That is, we desire a function $f$ such that $f(f(x)) = e^x$, at least asymptotically. There are slight technical difficulties with finding a function which exactly satisfies $f(f(x)) = e^x$, but it turns out that we can find a nice bijective function $f : [0,\infty) \rightarrow [0,\infty)$ which satisfies
\[
f(f(x)) = e^x - 1.
\]
The advantage of using $e^x - 1$ here is that $e^0 - 1 = 0$, so we can set $f(0) = 0$.

We define a pair of functions $\varepsilon(x)$ and $\ell(x)$ by
\[
\varepsilon(x) = e^x - 1
\]
and
\[
\ell(x) = \ln(1 + x),
\]
and note that $\varepsilon, \ell : [0,\infty) \rightarrow [0,\infty)$ are inverse bijections.

For each $n \in \NN$, we define $\varepsilon^n(x)$ and $\ell^n(x)$ to be the $n$th iterates of $\varepsilon$ and $\ell$, so that $\varepsilon^0(x) = \ell^0(x) = x$ and $\varepsilon^{n+1}(x) = \varepsilon(\varepsilon^n(x)), \ell^{n+1}(x) = \ell(\ell^n(x))$. The strategy is to start by defining a bijective function $\ell^* : (0,\infty) \rightarrow \RR$ such that $\ell^*(1) = 0$,
\[
\ell^*(\varepsilon(x)) = \ell^*(x) + 1,
\]
and
\[
\ell^*(\ell(x)) = \ell^*(x) - 1.
\]
Intuitively, $\ell^*(x)$ is ``the number of times we have to apply $\ell$ to reach $1$''. Using $\ell^*$, we can then construct a function $\varepsilon^{1/2}$ which satisfies $\varepsilon^{1/2}(\varepsilon^{1/2}(x)) = e^x - 1$.

\begin{prop} For all $x > 0$, we have $\varepsilon(x) > x$ and $\ell(x) < x$. In particular, for any $x > 0$, we have $\lim_{n \rightarrow \infty} \ell^n(x) = 0$.
\end{prop}

The intuition for computing $\ell^*(x)$ is that we may use the identity
\[
\ell^*(\ell^n(x)) = \ell^*(x) - n
\]
to reduce the computation of $\ell^*(x)$ to the computation of $\ell^*(\ell^n(x))$. Since $\ell^n(x)$ is eventually quite close to $0$, we just need to understand how $\ell$ acts on numbers close to $0$. We can approximate $\ell(x)$ for small $x$ by the Taylor series
\[
\ell(x) = x - \frac{x^2}{2} + O(x^3).
\]
Comparing $\frac{1}{\ell(x)}$ to $\frac{1}{x}$, we get the following estimate.

\begin{prop} For $x$ small, we have
\[
\frac{1}{\ell(x)} = \frac{1}{x} + \frac{1}{2} - \frac{x}{12} + O(x^2).
\]
Additionally, we have
\[
\frac{1}{2} - \frac{x}{12} < \frac{1}{\ell(x)} - \frac{1}{x} < \frac{1}{2}
\]
for all $x > 0$.
\end{prop}
\begin{proof} The first statement follows from standard power series manipulation:
\[
\frac{1}{x - x^2/2 + x^3/3 - x^4/4 + x^5/5 - \cdots} = \frac{1}{x} + \frac{1}{2} - \frac{x}{12} + \frac{x^2}{24} - \frac{19x^3}{720} + \cdots.
\]

The inequality $\frac{1}{\ell(x)} - \frac{1}{x} < \frac{1}{2}$ is equivalent to
\[
\ell(x) > \frac{1}{1/x + 1/2} = 2 - \frac{4}{2+x},
\]
and since this is true for $x$ sufficiently close to $0$, we just need to check that the derivative of the left hand side is at least the derivative of the right hand side. Thus we just need to check that
\[
\frac{1}{1+x} > \frac{4}{(2+x)^2},
\]
which follows by multiplying out.

We only need to check the inequality $\frac{1}{2} - \frac{x}{12} < \frac{1}{\ell(x)} - \frac{1}{x}$ in the range $0 < x < 6$, and in this range it is equivalent to
\[
\ell(x) < \frac{1}{1/x + 1/2 - x/12} = \frac{x}{1 + x/2 - x^2/12}.
\]
Again, this is true for $x$ sufficiently close to $0$, so we may compare the derivatives instead. We see that we just need to check that
\[
\frac{1}{1+x} < \frac{(1 + x/2 - x^2/12) - x(1/2 - x/6)}{(1 + x/2 - x^2/12)^2} = \frac{1 + x^2/12}{(1 + x/2 - x^2/12)^2}
\]
for $0 < x < 6$. Multiplying out, this becomes
\[
(1 + x/2 - x^2/12)^2 < (1+x)(1 + x^2/12),
\]
or
\[
1 + x + \frac{x^2}{12} - \frac{x^3}{12} + \frac{x^4}{144} < 1 + x + \frac{x^2}{12} + \frac{x^3}{12},
\]
which holds for $0 < x < 24$.
\end{proof}

\begin{cor} For $x \le 1$, we have
\[
\frac{5n}{12} < \frac{1}{\ell^n(x)} - \frac{1}{x} < \frac{n}{2}.
\]
\end{cor}

\begin{cor} For $x \le 1$, we have
\[
\frac{1}{\ell^n(x)} = \frac{1}{x} + \frac{n}{2} - \sum_{i < n} \frac{\ell^i(x)}{12} + O(x).
\]
\end{cor}

\begin{cor} For $x \le 1$, we have
\[
\frac{1}{\ell^n(x)} = \frac{1}{x} + \frac{n}{2} - O(\ln(n)).
\]
\end{cor}

\begin{cor} For $x$ fixed and $n$ going to infinity, we have
\[
\frac{1}{\ell^n(x)} = \frac{n}{2} - \frac{\ln(n)}{6} + O_x(1).
\]
\end{cor}

So one natural path to computing $\ell^*(x)$ is to try to compute
\[
\lim_{n \rightarrow \infty} n - \frac{\ln(n)}{3} - \frac{2}{\ell^n(x)}.
\]
A simpler approach is to compare $\frac{2}{\ell^n(x)}$ to $\frac{2}{\ell^n(1)}$.

\begin{prop} For any $x, y > 0$, we have
\[
\Big|\frac{1}{x} - \frac{1}{y}\Big| \le \Big|\frac{1}{\ell(x)} - \frac{1}{\ell(y)}\Big| \le \Big|\frac{1}{x} - \frac{1}{y}\Big| + \frac{|x-y|}{12}.
\]
\end{prop}
\begin{proof} We just need to show that the function $f(x) = -1/\ell(x)$ has derivative bounded below by $\frac{1}{x^2}$ and above by $\frac{1}{x^2} + \frac{1}{12}$. We have
\[
f'(x) = \frac{1}{1+x}\cdot \frac{1}{\ell(x)^2}.
\]
Thus, for the left hand inequality, we just need to check that
\[
\ell(x)^2 < \frac{x^2}{1+x},
\]
or equivalently
\[
\ell(x) < \frac{x}{(1+x)^{1/2}}.
\]
Since equality holds at $0$, it's enough to compare the derivatives: we just need to show that
\[
\frac{1}{1+x} < \frac{1}{(1+x)^{1/2}} - \frac{x}{2(1+x)^{3/2}}.
\]
Multiplying out, this becomes
\[
2\sqrt{1+x} < 2+x,
\]
and squaring both sides shows that this holds for all $x > 0$.

For the right hand inequality, we need to check that
\[
\ell(x)^2 > \frac{x^2}{(1+x)(1+x^2/12)},
\]
or equivalently that
\[
\ell(x) > \frac{x}{(1+x)^{1/2}(1+x^2/12)^{1/2}}.
\]
Again, it's enough to compare the derivatives, so we just need to check that
\[
\frac{1}{1+x} > \frac{1}{(1+x)^{1/2}(1+x^2/12)^{1/2}} - \frac{x}{2(1+x)^{3/2}(1+x^2/12)^{1/2}} - \frac{x^2}{12(1+x)^{1/2}(1+x^2/12)^{3/2}}.
\]
Multiplying out, this becomes
\[
(1+x)^{1/2}(1+x^2/12)^{3/2} > 1 + x/2 - x^3/24,
\]
and on squaring both sides we get the inequality
\[
(1+x)(1+x^2/12)^3 > 1 + x + x^2/4 - x^3/12 - x^4/24 + x^6/24^2,
\]
which the reader may verify by using the inequality $x^5 + x^7 \ge 2x^6$.
\end{proof}

\begin{cor} For any $x, y > 0$, the limit
\[
\lim_{n \rightarrow \infty} \frac{2}{\ell^n(y)} - \frac{2}{\ell^n(x)}
\]
exists, and is equal to
\[
\lim_{n \rightarrow \infty} \frac{n^2}{2}\Big(\ell^n(x) - \ell^n(y)\Big).
\]
\end{cor}
\begin{proof} To see that the limit exists, note that if $x \ge y$, then the sequence
\[
\frac{2}{\ell^n(y)} - \frac{2}{\ell^n(x)}
\]
is increasing in $n$ and is bounded above by
\[
\frac{2}{y} - \frac{2}{x} + \sum_{m \ge 0} \frac{\ell^m(x) - \ell^m(y)}{6} \le \frac{2}{y} - \frac{2}{x} + \frac{kx}{6},
\]
where $k$ is any integer which satisfies $y \ge \ell^k(x)$.

For the second statement, note that
\[
\frac{2}{\ell^n(y)} - \frac{2}{\ell^n(x)} = \frac{2(\ell^n(x) - \ell^n(y))}{\ell^n(x)\ell^n(y)},
\]
and use the asymptotic
\[
\ell^n(x) = (1+o_x(1))\frac{2}{n}
\]
(and similarly for $y$) to replace the denominator by $4/n^2$.
\end{proof}

\begin{defn} For $x > 0$, we define $\ell^*(x)$ by
\[
\ell^*(x) = \lim_{n \rightarrow \infty} \frac{2}{\ell^n(1)} - \frac{2}{\ell^n(x)} = \lim_{n \rightarrow \infty} \frac{n^2}{2}\Big(\ell^n(x) - \ell^n(1)\Big).
\]
\end{defn}

\begin{prop} For all $x > 0$, the function $\ell^*(x)$ satisfies
\[
\ell^*(e^x - 1) = \ell^*(x) + 1
\]
and
\[
\ell^*(\ln(1+x)) = \ell^*(x) - 1.
\]
\end{prop}
\begin{proof} It's enough to prove the second statement. By the definition of $\ell^*$, we have
\[
\ell^*(x) - \ell^*(\ell(x)) = \lim_{n \rightarrow \infty} \frac{2}{\ell^{n+1}(x)} - \frac{2}{\ell^n(x)}.
\]
Setting $y_n = \ell^n(x)$, we have $y_n \rightarrow 0$, so the above is equal to
\[
\lim_{y \rightarrow 0} \frac{2}{\ell(y)} - \frac{2}{y} = 1.\qedhere%= \lim_{y_n \rightarrow 0} 1 - \frac{y_n}{6} + O(y_n^2) 
\]
\end{proof}

For the sake of concretely approximating $\ell^*$, we have the following explicit bound.

\begin{prop} If $x \ge y \ge \ell^k(x)$, then for any $n$ we have
\[
\frac{2}{\ell^n(y)} - \frac{2}{\ell^n(x)} \le \ell^*(x) - \ell^*(y) \le \frac{2}{\ell^n(y)} - \frac{2}{\ell^n(x)} + \frac{k\ell^n(x)}{6}.
\]
\end{prop}

Of course, we'd like to know if the function $\ell^*$ is well-behaved: is it continuous, is it differentiable, etc. To answer this question, we use the theory of \emph{completely monotone}/\emph{Bernstein} functions.

\begin{defn} A continuous function $f : [0,\infty) \rightarrow \RR$ is called \emph{completely monotone} if it satisfies
\[
(-1)^nf^{(n)}(x) \ge 0
\]
for all $x > 0$ and all $n \in \NN$.

A function $g : [0,\infty) \rightarrow [0,\infty)$ whose derivative is completely monotone is called a \emph{Bernstein function}.

A function $h$ such that $h^{(n)}(x) \ge 0$ for all $x$ and all $n \in \NN$ is called \emph{absolutely monotone}. If $h$ is absolutely monotone on $(-\infty, 0]$, then $h(-x)$ is completely monotone, and conversely.
\end{defn}

\begin{prop} If $f,g$ are Bernstein, then the composition $f \circ g$ is also a Bernstein function. If $f$ is completely monotone and $g$ is Bernstein, then $f \circ g$ is completely monotone.
\end{prop}

\begin{cor} For every $n$, the function $\ell^n$ is a Bernstein function, and $1/\ell^n$ is a completely monotone function.
\end{cor}

The next result follows easily from standard facts about divided differences, but I haven't seen it explicitly stated anywhere (aside from the special cases we use here).

\begin{prop} If $f$ is a pointwise limit of functions $f_i$ such that for each $n \ge 1$, the derivatives $f_i^{(n)}$ exist and have a fixed sign $s_n \in \{+,-\}$ not depending on $i$, then each derivative $f^{(n)}$ exists and has the same fixed sign $s_n$. In this case, we even have
\[
f^{(n)}(x) = \lim_{i\rightarrow \infty} f_i^{(n)}(x).
\]
In particular, any pointwise limit of Bernstein functions is a Bernstein function, and the same holds for completely monotone functions.
\end{prop}

%One of the main results about completely monotone functions is that they can be represented as Laplace transforms of positive measures on $(0,\infty)$. Using this fact together with the fact that the exponential function extends to the complex plane, we can extend any completely monotone function to a function which takes complex arguments.

Using direct arguments, one can show that if $f$ is completely monotone on $(0,\infty)$ then for every $x > 0$, the Taylor series of $f$ around $x$ has radius of convergence at least as large as $x$, and converges to $f$ on the interval $(0,x]$. This quickly leads to the following result.

\begin{prop}[\cite{laplace}] Every completely monotone function $f : (0,\infty) \rightarrow \RR$ extends to an analytic function on the halfplane $\Re(x) > 0$, as does any Bernstein function. If $f$ is completely monotone on $(0,\infty)$ and $\Re(x) > 0$, then $|f(x)| \le f(\Re(x))$.
\end{prop}

\begin{cor} The function $\ell^*$ has completely monotone derivative, and extends to an analytic function on the halfplane $\Re(x) > 0$. For all $n \ge 1$ and $\Re(x) > 0$, we have
\[
|\ell^{*(n)}(x)| \le (-1)^{n-1}\ell^{*(n)}(\Re(x)).
\]
\end{cor}

Using standard facts about Taylor series, we can show that if $f(x) = \lim_{i\rightarrow \infty} f_i(x)$ is a pointwise limit of completely monotone (or Bernstein) functions $f_i$ on $(0,\infty)$, and if we extend each $f_i$ to a complex analytic function on $\Re(x) > 0$, then the extension of $f$ to an analytic function on $\Re(x) > 0$ also satisfies
\[
f(x) = \lim_{i\rightarrow \infty} f_i(x),
\]
and the convergence is uniform on compact subsets of the halfplane $\Re(x) > 0$. As a consequence, we get the formula
\[
\ell^*(x) = \lim_{n\rightarrow \infty} \frac{2}{\ell^n(1)} - \frac{2}{\ell^n(x)}
\]
for all complex $x$ with $\Re(x) > 0$.

Using the functional equation $\ell^*(x) = \ell^*(\ell(x)) - 1$, we can extend $\ell^*$ to an analytic function on $\CC \setminus (-\infty,0]$. For this to make sense, we need to first extend $\ell$ to an analytic function on $\CC\setminus(-\infty,-1]$ - we do this in the usual way, by integrating $x \mapsto \frac{1}{1+x}$ along paths contained in the region $\CC\setminus(-\infty,-1]$. This extension of $\ell$ takes the halfplane $\Re(x) > 0$ into itself, satisfies
\[
\ell\big(\CC \setminus (-\infty,0]\big) \subseteq \CC \setminus (-\infty,0],
\]
and satisfies
\[
|\Im(\ell(x))| < \pi
\]
for all $x \in \CC \setminus (-\infty,0]$.

\begin{prop} The function $\ell^*$ extends to an anaytic function on $\CC \setminus (-\infty,0]$, which satisfies the functional equation $\ell^*(x) = \ell^*(\ell(x)) + 1$ for all $x \in \CC \setminus (-\infty,0]$. This extension of $\ell^*$ is still given by the formula
\[
\ell^*(x) = \lim_{n\rightarrow \infty} \frac{2}{\ell^n(1)} - \frac{2}{\ell^n(x)}
\]
on $\CC \setminus (-\infty,0]$.
\end{prop}
\begin{proof} Since we already have an extension of $\ell^*$ to the halfplane $\Re(x) > 0$, we just need to check that for every $x \in \CC\setminus(-\infty,0]$, there is some $n \in \NN$ such that $\Re(\ell^n(x)) > 0$. For $x$ such that $|1+x| > 1$, we have
\[
\Re(\ell(x)) = \ln|1+x| > 0,
\]
so we just need to check that for every $x$ there is some $n$ with $|1+\ell^n(x)| > 1$. To prove this, we will first show that for $|1 + x| \le 1$ and $\Im(x) \ne 0$, we always have
\[
|\Im(\ell(x))| > |\Im(x)|.
\]
To see this, suppose that $\Im(x) > 0$, and consider the right triangle with vertices $-1$, $\Re(x)$, and $x$ in the complex plane. If $\theta$ is the angle of this triangle at the vertex $-1$, then we have $\Im(\ell(x)) = \theta$, and
\[
\Im(x) = |1+x|\sin(\theta) \le \sin(\theta) \le \theta = \Im(\ell(x)),
\]
with equality only when $\theta = 0$.

Now suppose for a contradiction that $|1 + \ell^n(x)| \le 1$ for all $n$. Suppose without loss of generality that $\Im(x) > 0$. Then the sequence $n \mapsto \Im(\ell^n(x))$ is an increasing sequence, so all of the points $\ell^n(x)$ are contained in the compact region
\[
C = \{z : |1+z| \le 1, \Im(z) \ge \Im(x) > 0\}.
\]
In particular, the sequence of points $\ell^n(x)$ must have some limit point $z \in C$, and since $\ell$ is continuous we must then have $\ell(z) = z$. But this is impossible, since we've proved that $\Im(\ell(z)) > \Im(z)$ for all $z \in C$. The contradiction proves that there must be some $n \in \NN$ such that $|1+\ell^n(x)| > 1$, and then we have $\Re(\ell^{n+1}(x)) > 0$ for the same $n$.
\end{proof}

The extension of $\ell^*$ to $\CC \setminus (-\infty,0]$ has
\begin{align*}
\lim_{\epsilon \rightarrow 0} \ell^*(-1 + i\epsilon) &= 1 + \lim_{x \rightarrow \infty} \ell^*\Big(-x + \frac{\pi i}{2}\Big)\\
&= 2 + \lim_{x \rightarrow \infty} \ell^*(x + (\pi + o(1)) i)\\
&= 2 + \lim_{x \rightarrow \infty} \ell^*(x) + O({\ell^*}'(x))\\
&= +\infty.
\end{align*}
Using the functional equation $\ell^*(x) = \ell^*(\ell(x)) + 1$, we get
\[
\lim_{\epsilon \rightarrow 0} \ell^*(\varepsilon^n(-1) + i\epsilon) = +\infty
\]
for each $n \in \NN$, and since the sequence $\varepsilon^n(-1)$ approaches $0$ from below, we see that $\ell^*$ has an essential singularity at $0$.

The function $\ell^*$ can be further extended to a multivalued function on
\[
\CC \setminus (\{0\}\cup\{\varepsilon^n(-1) : n \in \NN\}).
\]
More precisely, we can extend $\ell^*$ to an analytic function on a infinitely branched cover of $\CC$ with branch points lying above $\varepsilon^n(-1)$ for $n \in \NN$ (we make branch cuts along $(-\infty,-1), (-1,\varepsilon(-1)), ...$). One way to make this precise is to consider the set of continuous paths
\[
p : [0,1] \rightarrow \CC\setminus \{\varepsilon^n(-1) : n \in \NN\}
\]
with $p(0) \in (0,\infty)$ and $p(1) = x$ instead of just points $x$. We can apply $\ell$ to any such path $p$ to get another such path $\ell(p)$, and as we will soon see, if we apply $\ell$ sufficiently many times then eventually the path $\ell^n(p)$ will be entirely contained in the halfplane $\Re(x) > 0$.

As it turns out the set of paths $p$ we have to consider (or equivalently, the set of sheets of the branched cover) is simpler than expected: if a path $p$ starts out by looping counterclockwise around $-1$ even one time, we will have $\Im(\ell(p)) > \pi$ from there on, so
\[
\ell^*(p) = \ell^*(\ell(p)) + 1
\]
can be defined straightforwardly from that point on without worrying about $p$ hitting any other branch points. Similar reasoning applied to $\ell^n(p)$ shows that if $p$ begins by looping counterclockwise around any $\varepsilon^n(-1)$, we don't have to worry about hitting any $\varepsilon^{n+k}(-1)$ for any $k \ge 1$, although we do still have to worry about hitting $\varepsilon^m(-1)$ for $m \le n$. Representative paths $p$ for the various sheets of the cover can be described by sequences
\[
(w_0, w_1, ..., w_n, 0, ...)
\]
of integer winding numbers which are eventually $0$, with the following interpretation: if $w_n$ is the last nonzero winding number in the sequence, then the sequence of winding numbers describes the path that \emph{first} winds $w_n$ times counterclockwise around $\varepsilon^n(-1)$, \emph{second} winds $w_{n-1}$ times counterclockwise around $\varepsilon^{n-1}(-1)$, ..., and \emph{finally} winds $w_0$ times counterclockwise around $-1$. When we apply $\ell$ to a path $p$, the winding number sequence simplifies:
\[
p \leftrightarrow (w_0, w_1, w_2, ..., w_n, 0, ...) \;\; \implies \;\; \ell(p) \leftrightarrow (w_1, w_2, ..., w_n, 0, 0, ...).
\]
To see this, just note that $\Im(x)$ and $\Im(\ell(x))$ always have the same sign as long as we stay in the halfplane $\Re(x) > -1$, so every loop of $p$ around $\varepsilon^n(-1)$ gets mapped by $\ell$ to a loop of $\ell(p)$ around $\varepsilon^{n-1}(-1)$. After applying $\ell$ to $p$ exactly $n+1$ times, we get a path $\ell^{n+1}(p)$ which is entirely contained in $\CC \setminus (-\infty,0]$, and we have already extended $\ell^*$ to an analytic function on this region.

Now we turn to the task of computing values of $\ell^*$ to higher accuracy. Since applying $\ell$ repeatedly always takes us close to $0$, and since we have the reference values $\ell^*(\ell^n(1)) = -n$, we just need to find more accurate approximations to ${\ell^*}'(x)$ for $x$ close to $0$. Unfortunately, the essential singularity of $\ell^*$ at $0$ implies that there is no Laurent series which computes $\ell^*$ (or any of its derivatives) in any punctured disk around $0$. Nevertheless, we will show that there is an asymptotic series for the derivative of $\ell^*$ around $0$, beginning with
\[
\frac{d}{dx}\ell^*(x) = \frac{2}{x^2} + \frac{1}{3x} - \frac{1}{36} + \frac{x}{270} + \frac{x^2}{2592} - \frac{71x^3}{108864} + \frac{8759x^4}{32659200} + \frac{31x^5}{3499200} + O(x^6)
\]
for $x > 0$. Further terms of the asymptotic series can be computed by expanding the functional equation
\[
{\ell^*}'(x) = \frac{{\ell^*}'(\ell(x))}{1+x}
\]
as if both sides were formal Laurent series and equating coefficients. Explicit error terms in the asymptotic series can be computed using the theory of divided differences - this can be useful for getting the most accurate possible approximation when numerically computing $\ell^*$.

\begin{prop} For each $k \in \NN$, define $A_k(x)$ by
\[
A_k(x) \coloneqq \sum_{i=1}^k \frac{i}{x - \ell^i(x)}\prod_{\substack{j \le k \\ j\ne i}}\frac{x-\ell^j(x)}{\ell^i(x)-\ell^j(x)}.
\]
Then for every $k \in \NN$ we have
\[
{\ell^*}'(x) = A_k(x) + O(x^{k-2})
\]
as $x$ approaches $0$ from above, and for all $x \in (0,\infty)$ we have
\[
A_{2k}(x) \le {\ell^*}'(x) \le A_{2k+1}(x).
\]
In particular, since each $A_k(x)$ has a Laurent series with rational coefficients which converges in a punctured disk around $0$ of positive radius, ${\ell^*}'(x)$ has an asymptotic series with rational coefficients as $x$ approaches $0$ from above.
\end{prop}
\begin{proof} We use the theory of divided differences. For $f$ a function on $(0,\infty)$, we set $f[x] \coloneqq f(x)$, and recursively
\[
f[x_1, ..., x_{n+1}] \coloneqq \frac{f[x_1, ..., x_{n-1},x_n] - f[x_1, ..., x_{n-1},x_{n+1}]}{x_n - x_{n+1}}.
\]
If two entries $x_i, x_j$ are equal, then we define the divided difference by taking a suitable limit (this will be well-defined as long as $f$ is sufficiently differentiable).

Using $\ell^*(x) - \ell^*(\ell^i(x)) = i$, a standard computation gives
\[
\ell^*[x,x,\ell(x),...,\ell^k(x)] = \frac{{\ell^*}'(x)}{\prod_{i=1}^k(x-\ell^i(x))} - \sum_{i=1}^k \frac{i}{(x - \ell^i(x))^2\prod_{j\ne i}(\ell^i(x) - \ell^j(x))}.
\]
\begin{comment}
and
\[
\ell^*[\varepsilon(x),x,x,\ell(x),...,\ell^{k-1}(x)] = -\frac{{\ell^*}'(x)}{(\varepsilon(x)-x)\prod_{i=1}^{k-1}(x-\ell^i(x))} + \frac{-1}{(\varepsilon(x)-x)^2\prod_{j}(\varepsilon(x) - \ell^j(x))} - \sum_{i=1}^{k-1} \frac{i}{(\varepsilon(x)-\ell^i(x))(x - \ell^i(x))^2\prod_{j\ne i}(\ell^i(x) - \ell^j(x))} \ge 0.
\]
\end{comment}
By the mean value theorem for divided differences, there is some $\xi \in [\ell^k(x),x]$ such that
\[
\ell^*[x,x,\ell(x),...,\ell^k(x)] = {\ell^*}^{(k+1)}(\xi).
\]
By the fact that ${\ell^*}'$ is completely monotone, we have
\[
(-1)^k\ell^*[x,x,\ell(x),...,\ell^k(x)] = (-1)^k{\ell^*}^{(k+1)}(\xi) \ge 0,
\]
so depending on whether $k$ is even or odd, ${\ell^*}'(x)$ is either bounded below or above by
\[
A_k(x) \coloneqq \sum_{i=1}^k \frac{i}{x - \ell^i(x)}\prod_{j\ne i}\frac{x-\ell^j(x)}{\ell^i(x)-\ell^j(x)}.
\]
To finish the proof, we just need to check that
\[
{\ell^*}'(x) - A_k(x) = \ell^*[x,x,\ell(x),...,\ell^k(x)]\cdot\prod_{i=1}^k(x-\ell^i(x))
\]
is $O(x^{k-2})$. Since $x - \ell^i(x) \propto x^2$, this is equivalent to proving that
\[
\ell^*[x,x,\ell(x),...,\ell^k(x)] = {\ell^*}^{(k+1)}(\xi) \stackrel{?}{=} O(x^{-k-2}).
\]
By complete monotonicity of ${\ell^*}'$, we have
\[
{\ell^*}'(\xi/2) \ge \big|{\ell^*}^{(k+1)}(\xi)\big| \cdot \frac{(\xi/2)^k}{k!},
\]
and we already know that ${\ell^*}'(\xi/2) = O(\xi^{-2})$ by the concavity of $\ell^*$ and the fact that $\ell^n(1) =  \frac{2+o(1)}{n}$. Since $\xi = x - O(x^2)$, we have
\[
\big|{\ell^*}^{(k+1)}(\xi)\big| = O(\xi^{-k-2}) = O(x^{-k-2}),
\]
so we are done.
\begin{comment}
$A_k(x) - A_{k+1}(x) = O(x^{k-2})$ for each $k$.

Since each $A_k(x)$ is an honest Laurent series around $0$, if $A_k(x) - A_{k+1}(x)$ is \emph{not} $O(x^{k-2})$, then we must have $A_k(x) - A_{k+1}(x) = \Omega(x^{k-3})$ as $x$ approaches $0$. Since
\[
A_{k+1}(x) - A_k(x) = \ell^*[x,x,\ell(x),...,\ell^k(x)]\prod_{i=1}^k(x-\ell^i(x)) - \ell^*[x,x,\ell(x),...,\ell^{k+1}(x)]\prod_{i=1}^{k+1}(x-\ell^i(x))
\]
and $x - \ell^i(x) \propto x^2$ for each $i$, we see that if $A_k(x) - A_{k+1}(x) = \Omega(x^{k-3})$, then
\[
\max\Big(\big|\ell^*[x,x,\ell(x),...,\ell^k(x)]\big|x^{2k}, \big|\ell^*[x,x,\ell(x),...,\ell^{k+1}(x)]\big|x^{2k+2}\Big) = \Omega(x^{k-3}).
\]
By the mean value theorem for divided differences and the fact that $\ell^*$ is completely monotone, this implies that at each $x$ either ${\ell^*}^{(k+1)}(x) = \Omega(x^{-k-3})$ or ${\ell^*}^{(k+2)}(x) = \Omega(x^{-k-5})$. By complete monotonicity again, we see that if ${\ell^*}^{(k+2)}(x) = \Omega(x^{-k-5})$ then ${\ell^*}^{(k+1)}(x/2) = \Omega(x^{-k-4})$, so we must in fact have
\[
{\ell^*}^{(k+1)}(x) = \Omega(x^{-k-3})
\]
for all sufficiently small $x$. But then integrating this repeatedly gives $\ell^*(x) = \Omega(x^{-2})$, which contradicts $\ell^n(1) \propto 1/n$. This contradiction proves that we must in fact have
\[
{\ell^*}'(x) = A_k(x) + O(x^{k-2})
\]
for all $k$.
\end{comment}
\end{proof}

We can also prove a uniqueness result for $\ell^*$, using only the assumption of concavity together with the functional equation.

\begin{comment}
\begin{prop}[\cite{completely-monotone-uniqueness}] If $f, g$ are completely monotone and $f(x_n) = g(x_n)$ for a sequence $x_n$ such that $\sum_n 1/x_n$ diverges, then $f = g$. The same holds for functions with completely monotone derivatives. %TODO: is the extension to functions with completely monotone derivatives actually true??
\end{prop}

\begin{cor} If $f$ is a function with a completely monotone derivative which satisfies $f(\ell^n(1)) = -n$ for all $n \in \NN$, then $f = \ell^*$.
\end{cor}
\end{comment}

\begin{prop} If $f : (0,\infty) \rightarrow \RR$ is a concave function which satisfies $f(\ell(x)) = f(x) - 1$ for all $x > 0$, and if $f(1) = 0$, then $f = \ell^*$.
\end{prop}
\begin{proof} By the functional equation, it's enough to show that $f(x) - \ell^*(x) = O(x)$ as $x$ approaches $0$ from above. Since $f(\ell^n(1)) = -n = \ell^*(\ell^n(1))$ for $n \in \NN$, it's enough to show that the difference between $f(x) - f(y)$ and $\ell^*(x) - \ell^*(y)$ is $O(x)$ for $x > y > \ell(x)$. By the concavity of $f$, we have
\[
f[x,y,\ell(x)] \le 0
\]
and
\[
f[\varepsilon(x),x,y] \le 0,
\]
and expanding these inequalities out in the case $x > y > \ell(x)$ we get
\[
\frac{f(\varepsilon(x)) - f(x)}{\varepsilon(x) - x} \le \frac{f(x) - f(y)}{x-y} \le \frac{f(x) - f(\ell(x))}{x - \ell(x)}.
\]
By the functional equation $f(\ell(x)) = f(x) - 1$, we get
\[
\frac{1}{\varepsilon(x) - x} \le \frac{f(x) - f(y)}{x-y} \le \frac{1}{x - \ell(x)},
\]
and expanding the upper and lower bounds as Laurent series in $x$, we get
\[
\frac{f(x) - f(y)}{x-y} = \frac{2}{x^2} + O(1/x)
\]
as $x$ approaches $0$ from above. Since
\[
x-y \le x - \ell(x) = O(x^2),
\]
we have
\[
f(x) - f(y) = \frac{2(x-y)}{x^2} + O(x).
\]
Since the same reasoning applies to $\ell^*$ as well, we have $f(x) - f(y) = \ell^*(x) - \ell^*(y) + O(x)$ for all $x > y > \ell(x)$.
\end{proof}

We now define a real-analytic tetration function $\varepsilon^*$.

\begin{defn} We define $\varepsilon^* : \RR \rightarrow (0,\infty)$ to be the inverse function to $\ell^*$.
\end{defn}

Some of the nice properties of $\ell^*$ immediately imply nice properties of $\varepsilon^*$. Since $\ell^*$ is increasing and concave, $\varepsilon^*$ will be increasing and convex. Since $\ell^*(x)$ extends to a complex analytic function on $\CC\setminus (-\infty,0]$ which satisfies the functional equation $\ell^*(x) = \ell^*(\ell(x)) + 1$, $\varepsilon^*$ extends to a complex analytic function on some neighborhood of $\RR$ which satisfies the functional equation
\[
\varepsilon^*(x+1) = \varepsilon(\varepsilon^*(x)).
\]
The uniqueness property of $\ell^*$ implies that $\varepsilon^*$ is the unique convex function on $\RR$ which satisfies this functional equation together with the initial condition $\varepsilon^*(0) = 1$.

\begin{prop} For every $x \in \RR$, we have
\[
\varepsilon^*(x) = \lim_{n \rightarrow \infty} \varepsilon^{n}\Big(\frac{2}{\frac{2}{\ell^n(1)} - x}\Big).
\]
\end{prop}
\begin{proof} If $y = \varepsilon^*(x)$, then from $\ell^*(y) = x$ we see that
\[
\lim_{n \rightarrow \infty} \frac{2}{\ell^n(1)} - \frac{2}{\ell^n(y)} = x.
\]
By induction on $k$, using the inequality $|1/a - 1/b| \le |1/\ell(a) - 1/\ell(b)|$ which we proved earlier, we have
\[
\Big|\frac{2}{\ell^{n-k}(y)} - \frac{2}{\varepsilon^k(\frac{2}{\frac{2}{\ell^n(1)} - x})}\Big| \le \Big|\frac{2}{\ell^n(y)} - \Big(\frac{2}{\ell^n(1)} - x\Big)\Big|,
\]
so in particular we have
\[
\Big|\frac{2}{y} - \frac{2}{\varepsilon^n(\frac{2}{\frac{2}{\ell^n(1)} - x})}\Big| \le \Big|\frac{2}{\ell^n(y)} - \Big(\frac{2}{\ell^n(1)} - x\Big)\Big| = \Big|x - \Big(\frac{2}{\ell^n(1)} - \frac{2}{\ell^n(y)}\Big)\Big|.
\]
Taking the limit of both sides as $n \rightarrow \infty$ proves that
\[
\frac{2}{\varepsilon^*(x)} = \frac{2}{y} = \lim_{n\rightarrow \infty}\frac{2}{\varepsilon^n(\frac{2}{\frac{2}{\ell^n(1)} - x})}.\qedhere
\]
\end{proof}

\begin{cor} The function $\varepsilon^*$ is absolutely monotone, that is, ${\varepsilon^*}^{(n)}(x) \ge 0$ for every $n \in \NN$ and every $x \in \RR$.
\end{cor}
\begin{proof} From the fact that the function $x \mapsto \frac{2}{c-x}$ is absolutely monotone on $(-\infty, c)$ for every constant $c$, the fact that $\varepsilon(x)$ is absolutely monotone on $(0,\infty)$, and the fact that compositions of absolutely monotone functions are absolutely monotone, each function
\[
\varepsilon^{n}\Big(\frac{2}{\frac{2}{\ell^n(1)} - x}\Big)
\]
is absolutely monotone on $(-\infty, 2/\ell^n(1))$. Since pointwise limits of absolutely monotone functions are absolutely monotone, we see that $\varepsilon^*$ is absolutely monotone as well.
\end{proof}

\begin{cor} The function $\varepsilon^*$ extends to an entire function on $\CC$ which satisfies the functional equation $\varepsilon^*(x+1) = \varepsilon(\varepsilon^*(x))$. For all $x \in \CC$, we have
\[
\varepsilon^*(x) = \lim_{n \rightarrow \infty} \varepsilon^{n}\Big(\frac{2}{\frac{2}{\ell^n(1)} - x}\Big).
\]
\end{cor}

By Picard's little theorem, $\varepsilon^*$ can only avoid a single value on $\CC$, and since $\varepsilon(x) = e^x-1 \ne -1$ for all $x \in \CC$, the functional equation for $\varepsilon^*$ shows that
\[
\varepsilon^*(x) \ne -1
\]
for all $x \in \CC$ as well. Interestingly, this implies that $\varepsilon^*$ must instead take values such as $0$ and $\varepsilon(-1)$ - and in fact, Picard's great theorem implies that $\varepsilon^*$ takes these values infinitely often. This may not be such a surprise if you think back to our description of the extension of $\ell^*$ to a function on a branched cover of $\CC$ with infinitely many sheets, and use the fact that
\[
\varepsilon^*(\ell^*(x)) = x.
\]
For instance, the zeros of $\varepsilon^*$ are in one-to-one correspondence with the set of sheets of this branched covering, excluding the single starting sheet where $\ell^*$ has an essential singularity at $0$.

\begin{comment}
\[
|\frac{d}{dx}\frac{1}{e^{1/x}-1}| = |\frac{e^{1/x}}{x^2(e^{1/x}-1)^2}| < 1?
|e^{1/x}| < |x(e^{1/x}-1)|^2?
1 < |x^2(e^{1/x}-2+e^{-1/x})|?
|e^x + e^{-x} - 2| > |x|^2?
|x^2 + x^4/12 + ...| > |x|^2?
|1 + x^2/12 + ...| > 1?
\]
\end{comment}

Now we can finally define the fractional compositional powers of the function $e^x - 1$.

\begin{defn} For every $n \in \CC$, we define the function $\varepsilon^n : \CC \setminus (-\infty,0] \rightarrow \CC$ by
\[
\varepsilon^n(x) = \varepsilon^*(\ell^*(x) + n).
\]
We define $\ell^n$ by $\ell^n(x) = \varepsilon^{-n}(x)$.
\end{defn}

\begin{prop} For any $m,n \in \RR$ and any $x > 0$, we have
\[
\varepsilon^m(\varepsilon^n(x)) = \varepsilon^{m+n}(x).
\]
In particular, we have
\[
\varepsilon^{1/2}(\varepsilon^{1/2}(x)) = e^x - 1.
\]
\end{prop}

We can compute $\varepsilon^m$ with a direct limit formula, using the fact that the limit formulas for $\ell^*$ and $\varepsilon^*$ converge uniformly on compact subsets of their domains.

\begin{prop} For $m \in \CC$ and $x \in \CC \setminus (-\infty,0]$, we have
\[
\varepsilon^m(x) = \lim_{n \rightarrow \infty} \varepsilon^n\Big(\frac{2}{\frac{2}{\ell^n(x)} - m}\Big).
\]
\end{prop}

Just for fun, we can also define an asymptotic measurement of ``how exponentially'' a function grows.

\begin{defn} We say that a function $f:(0,\infty) \rightarrow (0,\infty)$ has \emph{exponentiality} $\alpha(f)$ if
\[
\alpha(f) = \lim_{x\rightarrow \infty} \ell^*(f(x)) - \ell^*(x) = \lim_{x \rightarrow \infty} \ell^*(f(\varepsilon^*(x))) - x.
\]
\end{defn}

Under this definition, we have $\alpha(1) = -\infty$, $\alpha(x) = 0$, $\alpha(\varepsilon) = 1$, and $\alpha(\ell) = -1$. Additionally, we have $\alpha(\varepsilon^n) = n$ for all $n \in \RR$, $\alpha{\ell^*} = -\infty$, and $\alpha(\varepsilon^*) = +\infty$.

\begin{prop} If $f,g : (0,\infty) \rightarrow [\epsilon,\infty)$ are functions with exponentialities $\alpha(f), \alpha(g)$, then
\[
\alpha(fg) = \alpha(f+g) = \max(\alpha(f),\alpha(g)).
\]
\end{prop}

\begin{prop} If $f,g : (0,\infty) \rightarrow (0,\infty)$ have exponentialities $\alpha(f), \alpha(g) > -\infty$, then
\[
\alpha(f \circ g) = \alpha(f) + \alpha(g).
\]
\end{prop}
\begin{proof} For any $x$, we have
\[
\ell^*(f(g(x))) - \ell^*(x) = \ell^*(f(g(x))) - \ell^*(g(x)) + \ell^*(g(x)) - \ell^*(x).
\]
Since $g(x)$ must go to $\infty$ as $x \rightarrow \infty$ if $\alpha(g) > -\infty$, we see that the limit of the above expression is $\alpha(f) + \alpha(g)$.
\end{proof}

\begin{cor} Every function which can be constructed (in finitely many steps) out of positive polynomials by addition, multiplication, exponentiation, and taking logarithms has an exponentiality in $\ZZ \cup \{-\infty\}$.
\end{cor}

\section{A slight generalization of the construction}

Now that we have defined $\ell^*$ and $\varepsilon^*$, it's tempting to try to iterate these functions as well. Perhaps we can find a half-tetration function? Immediately we run into the problem that $\ell^*(\ell^*(x))$ is not defined for $x = 1$, $x = \varepsilon^*(-1)$, etc. Actually, we had the same problem with iterating $\ln$ - we got around this problem by shifting the input by a convenient constant, to define the function $\ell$.

Since ${\ell^*}' : (0,\infty) \rightarrow (0,\infty)$ is a strictly decreasing continuous function with ${\ell^*}'(0+) = \infty$ and ${\ell^*}'(\infty) = 0$, there is a unique $x_0 \in (0,\infty)$ such that
\[
{\ell^*}'(x_0) = 1.
\]
Define a new function $\ell_0^*$ by
\[
\ell_0^*(x) = \ell^*(x + x_0) - \ell^*(x_0).
\]
Then $\ell_0^*$ has the following properties:
\begin{itemize}
\item $\ell_0^*(0) = 0$,
\item ${\ell_0^*}'(0) = 1$,
\item $\ell_0^*$ is a bijection from $(0,\infty)$ to itself,
\item $\ell_0^*$ is a Bernstein function,
\item the inverse function $\varepsilon_0^*$ to $\ell_0^*$ is given by
\[
\varepsilon_0^*(x) = \varepsilon^*(x + \ell^*(x_0)) - x_0,
\]
\item the function $\varepsilon_0^*$ is a bijection from $(-\infty,\infty)$ to $(-x_0,\infty)$,
\item the function $\varepsilon_0^*$ has an absolutely monotone derivative on $(-\infty,\infty)$.
\end{itemize}
These properties mirror the properties of $\ell, \varepsilon$ which were needed in order to iterate them.

\begin{comment}
f(g(x)) = x, and g has absolutely monotone derivative
then
g'f'(g) = 1 -> f' > 0
g''f'(g) + g'^2f''(g) = 0 -> f'' < 0
g'''f'(g) + 3g''g'f''(g) + g'^3f'''(g) = 0 -> ?
(g'''-3g''^2/g')f'(g) + g'^3f'''(g) = 0
\end{comment}

\begin{defn} Say that a pair of real functions $(f,g)$ is \emph{nicely iterable} if $f,g$ have the following properties:
\begin{itemize}
\item $g$ is defined on all of $\RR$,
\item $f$ is defined on the interval $(g(-\infty),\infty)$,
\item $f(g(x)) = x$ for all $x \in \RR$,
\item $f(0) = g(0) = 0$ and $f'(0) = g'(0) = 1$,
\item $f$ has a completely monotone derivative on its domain,
\item $g$ has an absolutely monotone derivative,
\item $f,g$ are not linear.
\end{itemize}
\end{defn}
We will write $f^n, g^n$ for the compositional powers of $f$ and $g$ (we will write ordinary powers of $f,g$ as $f(x)^n, g(x)^n$).

\begin{prop} Suppose that $(f,g)$ are nicely iterable. Then for every $x > 0$, we have $0 < f(x) < x$ and $\lim_{n\rightarrow\infty} f^n(x) = 0$.
\end{prop}
\begin{proof} That $f(x) \le x$ follows from $f'(0) = 1$ and $f$ concave. Suppose for contradiction that $f(x) = x$ for some $x > 0$, then we must have $f''(y) = 0$ for all $0 < y < x$, and since $f''$ is increasing and nonpositive, this implies that $f'' = 0$ on $(0,\infty)$. Since $f$ is analytic on its domain, this would imply that $f'' = 0$ identically, contradicting the assumption that $f$ is not linear.
\end{proof}

\begin{prop} Suppose that $(f,g)$ are nicely iterable. Then for $x,y > 0$ we have
\[
\frac{1}{f(x)} - \frac{1}{f(y)} = \frac{1}{x} - \frac{1}{y} + O(x-y).
\]
\end{prop}
\begin{proof} We just need to compare derivatives - more precisely, we need to check that
\[
\frac{f'(x)}{f(x)^2} = \frac{1}{x^2} + O(1).
\]
Since the left hand side is decreasing as a function of $x$, we only need to check this as $x$ approaches $0$. Since $f'$ is smooth in a neighborhood of $0$ and $f(0) = 0, f'(0) = 1$, we have
\[
f(x) = x - ax^2 + O(x^3)
%f(x) = x - ax^2 + bx^3 + O(x^4)
\]
for some $a$. Expanding, we have
\[
\frac{f'(x)}{f(x)^2} = \frac{1 - 2ax + O(x^2)}{x^2 - 2ax^3 + O(x^4)} = \frac{1}{x^2} + O(1).\qedhere
%\frac{f'(x)}{f(x)^2} = \frac{1 - 2ax + 3bx^2 + O(x^3)}{x^2 - 2ax^3 + (a^2+2b)x^4 + O(x^5)} = \frac{1}{x^2} + b-a^2 + O(x).\qedhere
\]
\end{proof}

\begin{cor} If $(f,g)$ are nicely iterable, then for $x > y > f^k(x) > 0$ and $n \ge 0$ we have
\[
\frac{1}{f^n(y)} - \frac{1}{f^n(x)} = \frac{1}{y} - \frac{1}{x} + O(kx),
\]
where the implied constant only depends on $f,g$. In particular, for any $x,y > 0$ the sequence
\[
n \mapsto \frac{1}{f^n(y)} - \frac{1}{f^n(x)}
\]
is a Cauchy sequence.
\end{cor}

\begin{prop} If $(f,g)$ are nicely iterable, then there is a unique concave function $f^*:(0,\infty) \rightarrow (-\infty,\infty)$ such that $f^*(1) = 0$ and
\[
f^*(x) = f^*(f(x)) + 1
\]
for all $x > 0$. This $f^*$ is given explicitly by the formula
\[
f^*(x) = \frac{2}{g''(0)}\lim_{n\rightarrow\infty} \frac{1}{f^{n}(1)} - \frac{1}{f^{n}(x)}.
\]
\end{prop}

\begin{prop} If $(f,g)$ are nicely iterable, then there is a unique convex function $g^*:(-\infty,\infty) \rightarrow (0,\infty)$ such that $g^*(0) = 1$ and
\[
g^*(x+1) = g(g^*(x))
\]
for all $x$. This $g^*$ is given explicitly by the formula
\[
g^*(x) = \lim_{n\rightarrow\infty} g^n\Big(\frac{2}{\frac{2}{f^n(1)} - g''(0)x}\Big).
\]
\end{prop}

\begin{prop} If $(f,g)$ are nicely iterable and $f^*, g^*$ are as in the previous results, then there is some $x_0 \in (0,\infty)$ such that if we define
\[
f_0^*(x) = f^*(x + x_0) - f^*(x_0)
\]
and
\[
g_0^*(x) = g^*(x + f^*(x_0)) - x_0,
\]
then the pair $(f_0^*,g_0^*)$ is nicely iterable as well.
\end{prop}

If we start with $(\ell,\varepsilon)$ and repeatedly apply the previous result, we get a sequence of absolutely monotone functions with growth rates climbing through the hierarchy of primitive recursive functions.

\bibliographystyle{plain}
\bibliography{all}

\end{document}

